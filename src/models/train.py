"""
Entra√Ænement Baseline : RandomForest + SVM avec MLflow tracking

EX√âCUTION:
    python src/models/train.py

R√âSULTAT ATTENDU:
    - 2 mod√®les entra√Æn√©s (RF + SVM)
    - M√©triques logg√©es dans MLflow
    - Mod√®les sauvegard√©s dans dossier 'models/'
"""

import os
import logging
import joblib
import numpy as np
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report
)
import mlflow
import mlflow.sklearn
import sys

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Ajouter le chemin du projet
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.data.load_data import DataLoader


class BaselineTrainer:
    """Entra√Æneur pour les mod√®les baseline"""
    
    def __init__(self, mlflow_uri="./mlruns"):
        """
        Initialiser le trainer
        
        Args:
            mlflow_uri: URI de MLflow (par d√©faut: local)
        """
        self.mlflow_uri = mlflow_uri
        
        # Configurer MLflow
        mlflow.set_tracking_uri(mlflow_uri)
        mlflow.set_experiment("cancer_baseline")
        
        logger.info(f"MLflow configur√©: {mlflow_uri}")
    
    def load_data(self):
        """
        Charger et pr√©processer les donn√©es
        
        Returns:
            X_train, X_test, y_train, y_test, scaler
        """
        logger.info("Chargement des donn√©es...")
        
        loader = DataLoader()
        X_train, X_test, y_train, y_test, scaler = loader.create_train_test_sets()
        
        logger.info(f"‚úì Donn√©es charg√©es:")
        logger.info(f"  - Train: {X_train.shape}")
        logger.info(f"  - Test: {X_test.shape}")
        logger.info(f"  - Classes: 0={sum(y_train==0)}, 1={sum(y_train==1)}")
        
        return X_train, X_test, y_train, y_test, scaler
    
    def train_random_forest(self, X_train, y_train, n_estimators=30, max_depth=10):
        """
        Entra√Æner RandomForest
        
        Args:
            X_train: Features d'entra√Ænement
            y_train: Labels d'entra√Ænement
            n_estimators: Nombre d'arbres
            max_depth: Profondeur maximale
            
        Returns:
            Mod√®le RandomForest entra√Æn√©
        """
        logger.info(f"Entra√Ænement RandomForest (n_est={n_estimators}, depth={max_depth})...")
        
        model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)
        
        logger.info("‚úì RandomForest entra√Æn√©")
        return model
    
    def train_svm(self, X_train, y_train, kernel='rbf', C=1.0):
        """
        Entra√Æner SVM
        
        Args:
            X_train: Features d'entra√Ænement
            y_train: Labels d'entra√Ænement
            kernel: Type de kernel
            C: Param√®tre de r√©gularisation
            
        Returns:
            Mod√®le SVM entra√Æn√©
        """
        logger.info(f"Entra√Ænement SVM (kernel={kernel}, C={C})...")
        
        model = SVC(kernel=kernel, C=C, probability=True, random_state=42)
        model.fit(X_train, y_train)
        
        logger.info("‚úì SVM entra√Æn√©")
        return model
    
    def evaluate(self, model, X_test, y_test, model_name="model"):
        """
        √âvaluer un mod√®le
        
        Args:
            model: Mod√®le √† √©valuer
            X_test: Features de test
            y_test: Labels de test
            model_name: Nom du mod√®le (pour logging)
            
        Returns:
            metrics (dict), y_pred
        """
        logger.info(f"√âvaluation {model_name}...")
        
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
        
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred),
            'recall': recall_score(y_test, y_pred),
            'f1': f1_score(y_test, y_pred),
        }
        
        if y_proba is not None:
            metrics['auc'] = roc_auc_score(y_test, y_proba)
        
        # Afficher les m√©triques
        logger.info(f"\n{model_name} Metrics:")
        for key, val in metrics.items():
            logger.info(f"  {key:12s}: {val:.4f}")
        
        return metrics, y_pred
    
    def log_to_mlflow(self, model, metrics, params, model_name, X_test, y_test, y_pred):
        """
        Logger le run dans MLflow
        
        Args:
            model: Mod√®le entra√Æn√©
            metrics: Dictionnaire des m√©triques
            params: Dictionnaire des param√®tres
            model_name: Nom du run
            X_test: Features de test
            y_test: Labels de test
            y_pred: Pr√©dictions
        """
        with mlflow.start_run(run_name=model_name):
            # Logger les param√®tres
            for key, val in params.items():
                mlflow.log_param(key, val)
            
            # Logger les m√©triques
            for key, val in metrics.items():
                mlflow.log_metric(key, val)
            
            # Logger le mod√®le
            mlflow.sklearn.log_model(model, "model")
            
            logger.info(f"‚úì Run '{model_name}' logg√© dans MLflow")
    
    def run_baseline(self):
        """Pipeline complet d'entra√Ænement baseline"""
        logger.info("\n" + "="*60)
        logger.info("üöÄ BASELINE TRAINING")
        logger.info("="*60 + "\n")
        
        # Charger les donn√©es
        X_train, X_test, y_train, y_test, scaler = self.load_data()
        
        # ===== RandomForest Baseline =====
        logger.info("\n1Ô∏è‚É£  RandomForest Baseline")
        logger.info("-" * 60)
        
        rf_model = self.train_random_forest(X_train, y_train, n_estimators=30, max_depth=10)
        rf_metrics, rf_pred = self.evaluate(rf_model, X_test, y_test, "RandomForest")
        rf_params = {
            'model': 'RandomForest',
            'n_estimators': 30,
            'max_depth': 10,
            'random_state': 42
        }
        
        self.log_to_mlflow(rf_model, rf_metrics, rf_params, "baseline_rf", X_test, y_test, rf_pred)
        
        # Sauvegarder
        Path("models").mkdir(exist_ok=True)
        joblib.dump(rf_model, "models/rf_baseline.pkl")
        logger.info("‚úì Mod√®le RandomForest sauvegard√©: models/rf_baseline.pkl")
        
        # ===== SVM Baseline =====
        logger.info("\n2Ô∏è‚É£  SVM Baseline")
        logger.info("-" * 60)
        
        svm_model = self.train_svm(X_train, y_train, kernel='rbf', C=1.0)
        svm_metrics, svm_pred = self.evaluate(svm_model, X_test, y_test, "SVM")
        svm_params = {
            'model': 'SVM',
            'kernel': 'rbf',
            'C': 1.0,
            'random_state': 42
        }
        
        self.log_to_mlflow(svm_model, svm_metrics, svm_params, "baseline_svm", X_test, y_test, svm_pred)
        
        # Sauvegarder
        joblib.dump(svm_model, "models/svm_baseline.pkl")
        logger.info("‚úì Mod√®le SVM sauvegard√©: models/svm_baseline.pkl")
        
        # ===== R√©sum√© =====
        logger.info("\n" + "="*60)
        logger.info("‚úÖ BASELINE TRAINING COMPLETED")
        logger.info("="*60)
        logger.info("\nR√©sum√©:")
        logger.info(f"  RandomForest F1: {rf_metrics['f1']:.4f}")
        logger.info(f"  SVM F1:          {svm_metrics['f1']:.4f}")
        logger.info(f"\nMod√®les sauvegard√©s:")
        logger.info(f"  - models/rf_baseline.pkl")
        logger.info(f"  - models/svm_baseline.pkl")
        logger.info(f"\nVisualiser les r√©sultats:")
        logger.info(f"  mlflow ui")
        logger.info("="*60 + "\n")
        
        return rf_model, svm_model


if __name__ == "__main__":
    trainer = BaselineTrainer()
    trainer.run_baseline()